<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Time-lagged autoencoders &#8212; deeptime 0.4.4+24.g9347b6b.dirty documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=822347c1" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=1e544560" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=8ffeb421" />
    <link rel="stylesheet" type="text/css" href="../_static/perfect-scrollbar/css/perfect-scrollbar.css?v=9f1a41f4" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <script src="../_static/documentation_options.js?v=ea547b4d"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/perfect-scrollbar/js/perfect-scrollbar.min.js?v=a8314474"></script>
    <script src="../_static/d3.v5.min.js?v=5b739c40"></script>
    <script src="../_static/d3-legend.min.js?v=5895a191"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="SINDy" href="sindy.html" />
    <link rel="prev" title="VAMPNets" href="vampnets.html" />
<link rel="apple-touch-icon" sizes="180x180" href="../_static/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../_static/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../_static/favicon-16x16.png">
<link rel="manifest" href="../_static/site.webmanifest">

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo/deeptime_romand_white.svg" alt="Logo"/>
    
  </a>
</p>










<!-- h3>Navigation</h3 -->
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index_dimreduction.html">Dimension reduction</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index_deepdimreduction.html">Deep dim reduction</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="vampnets.html">VAMPNets</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Time-lagged autoencoders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Autoencoders">Autoencoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Variational-autoencoders">Variational autoencoders</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sindy.html">SINDy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index_msm.html">Markov state models</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index_examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index_nbexamples.html">Notebook examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index_datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index_dev.html">For developers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/index_base.html">deeptime.base</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_clustering.html">deeptime.clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_sindy.html">deeptime.sindy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_covariance.html">deeptime.covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_decomposition.html">deeptime.decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_markov.html">deeptime.markov</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_markov_hmm.html">deeptime.markov.hmm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_markov_tools.html">deeptime.markov.tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_basis.html">deeptime.basis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_kernels.html">deeptime.kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_data.html">deeptime.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_plots.html">deeptime.plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_numeric.html">deeptime.numeric</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_util.html">deeptime.util</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../imprint.html">Imprint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">Software License</a></li>
</ul>





<!--
<p>
    <iframe src="https://ghbtns.com/github-btn.html?user=deeptime-ml&repo=deeptime&type=star&count=true&size=large&v=2"
            allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>
--><p class="caption">
    <span class="caption-text">Version</span>
</p>
<ul>
    <li class="toctree-l1">
        <a class="reference internal" id="version-latest"
           href="../latest/../index.html">Latest release
            (0.4.4)</a>
    </li>
    <li class="toctree-l1">
        <a class="reference internal" id="version-trunk"
           href="../trunk/../index.html">Trunk version</a>
    </li>
</ul>
<script>
    if (window.location.href.indexOf("latest") > -1) {
        document.getElementById("version-latest").className = "reference internal current";
        document.getElementById("version-trunk").className = "reference internal";
    } else {
        document.getElementById("version-latest").className = "reference internal";
        document.getElementById("version-trunk").className = "reference internal current";
    }
</script><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../contents.html">Documentation overview</a><ul>
  <li><a href="../index_deepdimreduction.html">Deep dim reduction</a><ul>
      <li>Previous: <a href="vampnets.html" title="previous chapter">VAMPNets</a></li>
      <li>Next: <a href="sindy.html" title="next chapter">SINDy</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" placeholder="Quick search" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script><div class="github-wrapper">
    <a href="https://github.com/deeptime-ml/deeptime"
       style="width: 16rem; height:100%; position:absolute; top:0; left:0;">
        <img class="side-logo logo-github" src="../_static/GitHub-Mark-Light-32px.png" alt="gh"/>
        <div style="display: table; height: 100%; overflow: hidden;">
            <div style="display: table-cell; vertical-align: middle;">
                <div>deeptime &#64; GitHub
                </div>
            </div>
        </div>
    </a>
</div>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="Time-lagged-autoencoders">
<h1>Time-lagged autoencoders<a class="headerlink" href="#Time-lagged-autoencoders" title="Link to this heading">¶</a></h1>
<p>For users already familiar with the time-lagged autoencoders interface: The corresponding API docs <a class="reference internal" href="../api/generated/deeptime.decomposition.deep.TAE.html"><span class="doc">TAE</span></a> and <a class="reference internal" href="../api/generated/deeptime.decomposition.deep.TVAE.html"><span class="doc">TVAE</span></a>.</p>
<p>Time-lagged autoencoders <a class="footnote-reference brackets" href="#footcite-wehmeyer2018timelagged" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> are a type of neural network approach which tries to first compress / encode instantaneous data through a function</p>
<div class="math">
\[E : \mathbb{R}^N \to \mathbb{R}^n, x_t\mapsto E(x_t)

\]</div>
<p>with <span class="math">\(N \geq n\)</span> and then reconstruct <span class="math">\(x_{t+\tau}\)</span> from <span class="math">\(E(x_t)\)</span> through a decoder network</p>
<div class="math">
\[D : \mathbb{R}^n \to \mathbb{R}^N, z \mapsto D(z).

\]</div>
<p>To this end, the optimization target is defined as the mean-squared error between <span class="math">\(x_{ t + \tau }\)</span> and <span class="math">\(D(E( x_t ))\)</span>.</p>
<p>By this, they differ from classical autoencoders which would try to reconstruct the instantaneous data.</p>
<p>In deeptime, time-lagged autoencoders come in two flavors, analogously to autoencoders and variational autoencoders <a class="footnote-reference brackets" href="#footcite-kingma2013auto" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>. To get started, we need to import <a class="reference external" href="https://pytorch.org/">PyTorch</a> as well as deeptime.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</pre></div>
</div>
</div>
<p>Also, we need to specify how many CPU threads to use and on what kind of device to train the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>This documentation explains the basic API of time-lagged autoencoders using sqrt-model data. It is a hidden two-state jump process with a two-dimensional observable emission distribution so that the two states cannot be linearly separated.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">deeptime.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">sqrt_model</span>

<span class="n">dtraj</span><span class="p">,</span> <span class="n">traj</span> <span class="o">=</span> <span class="n">sqrt_model</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">dtraj</span></code> are the discrete reference states and <code class="docutils literal notranslate"><span class="pre">traj</span></code> is the observable trajectory:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="mi">100</span><span class="p">),</span>
    <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]),</span> <span class="mi">100</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">kde_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">kernel</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="n">traj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">bw_method</span><span class="o">=</span><span class="mf">.1</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">kde_input</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dtraj</span><span class="p">[:</span><span class="mi">500</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Discrete trajectory&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;time (a.u.)&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Heatmap of observations&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_7_0.png" src="../_images/notebooks_tae_7_0.png" />
</div>
</div>
<p>To make life downstream a bit easier, we wrap the data into a <a class="reference external" href="../api/generated/deeptime.data.TimeLaggedDataset.rst#deeptime.data.TimeLaggedDataset">time-lagged dataset</a>, perform a train/validation set split, and create PyTorch data loaders:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">deeptime.util.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrajectoryDataset</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">TrajectoryDataset</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">traj</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">n_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">*</span><span class="mf">.5</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_val</span><span class="p">,</span> <span class="n">n_val</span><span class="p">])</span>

<span class="n">loader_train</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">loader_val</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">val_data</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="Autoencoders">
<h2>Autoencoders<a class="headerlink" href="#Autoencoders" title="Link to this heading">¶</a></h2>
<p>To define an ordinary autoencoder, encoder and decoder torch modules must be provided. To make things easier, deeptime offers the multi-layer preceptron as a building block:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">deeptime.util.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLP</span>

<span class="n">units</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">output_nonlinearity</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">,</span>
              <span class="n">initial_batchnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">units</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">initial_batchnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now all that is left to do is create a time-lagged autoencoder estimator and fit it on the data loaders.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">deeptime.decomposition.deep</span><span class="w"> </span><span class="kn">import</span> <span class="n">TAE</span>

<span class="n">tae</span> <span class="o">=</span> <span class="n">TAE</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">tae</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">loader_train</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">validation_loader</span><span class="o">=</span><span class="n">loader_val</span><span class="p">)</span>
<span class="n">tae_model</span> <span class="o">=</span> <span class="n">tae</span><span class="o">.</span><span class="n">fetch_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>The loss can be visualized and it can be seen, that our model does not overfit.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="o">*</span><span class="n">tae</span><span class="o">.</span><span class="n">train_losses</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="o">*</span><span class="n">tae</span><span class="o">.</span><span class="n">validation_losses</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_15_0.png" src="../_images/notebooks_tae_15_0.png" />
</div>
</div>
<p>The projection reveals a separation into two states</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">proj</span> <span class="o">=</span> <span class="n">tae_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">traj</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">proj</span><span class="p">[:</span><span class="mi">1000</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;matplotlib.lines.Line2D at 0x7f5ad72d93d0&gt;]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_17_1.png" src="../_images/notebooks_tae_17_1.png" />
</div>
</div>
<p>Coloring the data points according to the latent code reveals that the model managed to disentangle the sqrt-model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">traj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">proj</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cm</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_19_0.png" src="../_images/notebooks_tae_19_0.png" />
</div>
</div>
</section>
<section id="Variational-autoencoders">
<h2>Variational autoencoders<a class="headerlink" href="#Variational-autoencoders" title="Link to this heading">¶</a></h2>
<p>Instead of learning a deterministic forward mapping, in time-lagged variational autoencoders (TVAEs) a input distribution is mapped to a target distribution. To this end, the encoder maps to Gaussians and the decoder transforms the Gaussian distribution to the desired output distribution.</p>
<p>Since Gaussians are parameterized, the encoder maps not to a single latent code but to a mean vector and a log-variance vector, i.e., is expected to produce a tuple of tensors.</p>
<p>Again, deeptime provides a multilayer-perceptron-like architecture that performs this job:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">deeptime.decomposition.deep</span><span class="w"> </span><span class="kn">import</span> <span class="n">TVAEEncoder</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">TVAEEncoder</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">encoder</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
TVAEEncoder(
  (_sequential): Sequential(
    (0): Linear(in_features=2, out_features=100, bias=True)
    (1): ReLU()
    (2): Linear(in_features=100, out_features=100, bias=True)
    (3): ReLU()
  )
  (_to_mu): Linear(in_features=100, out_features=1, bias=True)
  (_to_logvar): Linear(in_features=100, out_features=1, bias=True)
)
</pre></div></div>
</div>
<p>The decoder can be an ordinary MLP as in the autoencoder case.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">initial_batchnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now, the TVAE can be constructed and trained.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">deeptime.decomposition.deep</span><span class="w"> </span><span class="kn">import</span> <span class="n">TVAE</span>

<span class="n">tvae</span> <span class="o">=</span> <span class="n">TVAE</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="n">tvae</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">loader_train</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">validation_loader</span><span class="o">=</span><span class="n">loader_val</span><span class="p">)</span>
<span class="n">tvae_model</span> <span class="o">=</span> <span class="n">tvae</span><span class="o">.</span><span class="n">fetch_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Also here we can have a look at the loss:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="o">*</span><span class="n">tvae</span><span class="o">.</span><span class="n">train_losses</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="o">*</span><span class="n">tvae</span><span class="o">.</span><span class="n">validation_losses</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_27_0.png" src="../_images/notebooks_tae_27_0.png" />
</div>
</div>
<p>And again, the network separates the two distributions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">traj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">tvae_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">traj</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cm</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_29_0.png" src="../_images/notebooks_tae_29_0.png" />
</div>
</div>
<p class="rubric">References</p>
<div class="docutils container" id="id3">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-wehmeyer2018timelagged" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Christoph Wehmeyer and Frank Noé. Time-lagged autoencoders: deep learning of slow collective variables for molecular kinetics. <em>J. Chem. Phys.</em>, 148(24):241703, jun 2018. <a class="reference external" href="https://doi.org/10.1063/1.5011399">doi:10.1063/1.5011399</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-kingma2013auto" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Diederik P Kingma and Max Welling. Auto-encoding variational bayes. <em>arXiv preprint arXiv:1312.6114</em>, 2013.</p>
</aside>
</aside>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
<script src="../_static/scrollbar.js"></script>

  </body>
</html>