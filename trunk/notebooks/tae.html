
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Time-lagged autoencoders &#8212; deeptime 0.4.0+8.gdd91e120 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/perfect-scrollbar/css/perfect-scrollbar.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/perfect-scrollbar/js/perfect-scrollbar.min.js"></script>
    <script src="../_static/perfect-scrollbar/js/perfect-scrollbar.min.js"></script>
    <script src="../_static/d3.v5.min.js"></script>
    <script src="../_static/d3-legend.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
    <script src="../_static/katex_autorenderer.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="SINDy" href="sindy.html" />
    <link rel="prev" title="VAMPNets" href="vampnets.html" />
<link rel="apple-touch-icon" sizes="180x180" href="../_static/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../_static/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../_static/favicon-16x16.png">
<link rel="manifest" href="../_static/site.webmanifest">

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo/deeptime_romand_white.svg" alt="Logo"/>
    
  </a>
</p>










<!-- h3>Navigation</h3 -->
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index_dimreduction.html">Dimension reduction</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index_deepdimreduction.html">Deep dim reduction</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="vampnets.html">VAMPNets</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Time-lagged autoencoders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Autoencoders">Autoencoders</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Variational-autoencoders">Variational autoencoders</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sindy.html">SINDy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index_msm.html">Markov state models</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index_examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/index.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index_dev.html">For developers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/index_base.html">deeptime.base</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_clustering.html">deeptime.clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_sindy.html">deeptime.sindy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_covariance.html">deeptime.covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_decomposition.html">deeptime.decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_markov.html">deeptime.markov</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_markov_hmm.html">deeptime.markov.hmm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_markov_tools.html">deeptime.markov.tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_basis.html">deeptime.basis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_kernels.html">deeptime.kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_data.html">deeptime.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_plots.html">deeptime.plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_numeric.html">deeptime.numeric</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index_util.html">deeptime.util</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../imprint.html">Imprint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">Software License</a></li>
</ul>





<!--
<p>
    <iframe src="https://ghbtns.com/github-btn.html?user=deeptime-ml&repo=deeptime&type=star&count=true&size=large&v=2"
            allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>
--><p class="caption">
    <span class="caption-text">Version</span>
</p>
<ul>
    <li class="toctree-l1">
        <a class="reference internal" id="version-latest"
           href="../latest/../index.html">Latest release
            (0.4.0)</a>
    </li>
    <li class="toctree-l1">
        <a class="reference internal" id="version-trunk"
           href="../trunk/../index.html">Trunk version</a>
    </li>
</ul>
<script>
    if (window.location.href.indexOf("latest") > -1) {
        document.getElementById("version-latest").className = "reference internal current";
        document.getElementById("version-trunk").className = "reference internal";
    } else {
        document.getElementById("version-latest").className = "reference internal";
        document.getElementById("version-trunk").className = "reference internal current";
    }
</script><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../contents.html">Documentation overview</a><ul>
  <li><a href="../index_deepdimreduction.html">Deep dim reduction</a><ul>
      <li>Previous: <a href="vampnets.html" title="previous chapter">VAMPNets</a></li>
      <li>Next: <a href="sindy.html" title="next chapter">SINDy</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" placeholder="Quick search" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script><div class="github-wrapper">
    <a href="https://github.com/deeptime-ml/deeptime"
       style="width: 16rem; height:100%; position:absolute; top:0; left:0;">
        <img class="side-logo logo-github" src="../_static/GitHub-Mark-Light-32px.png" alt="gh"/>
        <div style="display: table; height: 100%; overflow: hidden;">
            <div style="display: table-cell; vertical-align: middle;">
                <div>deeptime &#64; GitHub
                </div>
            </div>
        </div>
    </a>
</div>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="Time-lagged-autoencoders">
<h1>Time-lagged autoencoders<a class="headerlink" href="#Time-lagged-autoencoders" title="Permalink to this headline">¶</a></h1>
<p>For users already familiar with the time-lagged autoencoders interface: The corresponding API docs <a class="reference internal" href="../api/generated/deeptime.decomposition.deep.TAE.html"><span class="doc">TAE</span></a> and <a class="reference internal" href="../api/generated/deeptime.decomposition.deep.TVAE.html"><span class="doc">TVAE</span></a>.</p>
<p>Time-lagged autoencoders <a class="footnote-reference brackets" href="#footcite-wehmeyer2018timelagged" id="id1">1</a> are a type of neural network approach which tries to first compress / encode instantaneous data through a function</p>
<div class="math">
\[E : \mathbb{R}^N \to \mathbb{R}^n, x_t\mapsto E(x_t)

\]</div>
<p>with <span class="math">\(N \geq n\)</span> and then reconstruct <span class="math">\(x_{t+\tau}\)</span> from <span class="math">\(E(x_t)\)</span> through a decoder network</p>
<div class="math">
\[D : \mathbb{R}^n \to \mathbb{R}^N, z \mapsto D(z).

\]</div>
<p>To this end, the optimization target is defined as the mean-squared error between <span class="math">\(x_{ t + \tau }\)</span> and <span class="math">\(D(E( x_t ))\)</span>.</p>
<p>By this, they differ from classical autoencoders which would try to reconstruct the instantaneous data.</p>
<p>In deeptime, time-lagged autoencoders come in two flavors, analogously to autoencoders and variational autoencoders <a class="footnote-reference brackets" href="#footcite-kingma2013auto" id="id2">2</a>. To get started, we need to import <a class="reference external" href="https://pytorch.org/">PyTorch</a> as well as deeptime.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
<p>Also, we need to specify how many CPU threads to use and on what kind of device to train the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>This documentation explains the basic API of time-lagged autoencoders using sqrt-model data. It is a hidden two-state jump process with a two-dimensional observable emission distribution so that the two states cannot be linearly separated.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deeptime.data</span> <span class="kn">import</span> <span class="n">sqrt_model</span>

<span class="n">dtraj</span><span class="p">,</span> <span class="n">traj</span> <span class="o">=</span> <span class="n">sqrt_model</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">dtraj</span></code> are the discrete reference states and <code class="docutils literal notranslate"><span class="pre">traj</span></code> is the observable trajectory:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="mi">100</span><span class="p">),</span>
    <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]),</span> <span class="mi">100</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">kde_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">kernel</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="n">traj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">bw_method</span><span class="o">=</span><span class="mf">.1</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">kde_input</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dtraj</span><span class="p">[:</span><span class="mi">500</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Discrete trajectory&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;time (a.u.)&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;state&#39;</span><span class="p">)</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">);</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Heatmap of observations&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_7_0.png" src="../_images/notebooks_tae_7_0.png" />
</div>
</div>
<p>To make life downstream a bit easier, we wrap the data into a <a class="reference external" href="../api/generated/deeptime.data.TimeLaggedDataset.rst#deeptime.data.TimeLaggedDataset">time-lagged dataset</a>, perform a train/validation set split, and create PyTorch data loaders:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">deeptime.util.data</span> <span class="kn">import</span> <span class="n">TrajectoryDataset</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">TrajectoryDataset</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">traj</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">n_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">*</span><span class="mf">.5</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_val</span><span class="p">,</span> <span class="n">n_val</span><span class="p">])</span>

<span class="n">loader_train</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">loader_val</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">val_data</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="Autoencoders">
<h2>Autoencoders<a class="headerlink" href="#Autoencoders" title="Permalink to this headline">¶</a></h2>
<p>To define an ordinary autoencoder, encoder and decoder torch modules must be provided. To make things easier, deeptime offers the multi-layer preceptron as a building block:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deeptime.util.torch</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="n">units</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">output_nonlinearity</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">,</span>
              <span class="n">initial_batchnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">units</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">initial_batchnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now all that is left to do is create a time-lagged autoencoder estimator and fit it on the data loaders.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deeptime.decomposition.deep</span> <span class="kn">import</span> <span class="n">TAE</span>

<span class="n">tae</span> <span class="o">=</span> <span class="n">TAE</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">tae</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">loader_train</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">validation_loader</span><span class="o">=</span><span class="n">loader_val</span><span class="p">)</span>
<span class="n">tae_model</span> <span class="o">=</span> <span class="n">tae</span><span class="o">.</span><span class="n">fetch_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>The loss can be visualized and it can be seen, that our model does not overfit.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="o">*</span><span class="n">tae</span><span class="o">.</span><span class="n">train_losses</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="o">*</span><span class="n">tae</span><span class="o">.</span><span class="n">validation_losses</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_15_0.png" src="../_images/notebooks_tae_15_0.png" />
</div>
</div>
<p>The projection reveals a separation into two states</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">proj</span> <span class="o">=</span> <span class="n">tae_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">traj</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">proj</span><span class="p">[:</span><span class="mi">1000</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;matplotlib.lines.Line2D at 0x7f5ad72d93d0&gt;]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_17_1.png" src="../_images/notebooks_tae_17_1.png" />
</div>
</div>
<p>Coloring the data points according to the latent code reveals that the model managed to disentangle the sqrt-model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">traj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">proj</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cm</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_19_0.png" src="../_images/notebooks_tae_19_0.png" />
</div>
</div>
</section>
<section id="Variational-autoencoders">
<h2>Variational autoencoders<a class="headerlink" href="#Variational-autoencoders" title="Permalink to this headline">¶</a></h2>
<p>Instead of learning a deterministic forward mapping, in time-lagged variational autoencoders (TVAEs) a input distribution is mapped to a target distribution. To this end, the encoder maps to Gaussians and the decoder transforms the Gaussian distribution to the desired output distribution.</p>
<p>Since Gaussians are parameterized, the encoder maps not to a single latent code but to a mean vector and a log-variance vector, i.e., is expected to produce a tuple of tensors.</p>
<p>Again, deeptime provides a multilayer-perceptron-like architecture that performs this job:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deeptime.decomposition.deep</span> <span class="kn">import</span> <span class="n">TVAEEncoder</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">TVAEEncoder</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">encoder</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
TVAEEncoder(
  (_sequential): Sequential(
    (0): Linear(in_features=2, out_features=100, bias=True)
    (1): ReLU()
    (2): Linear(in_features=100, out_features=100, bias=True)
    (3): ReLU()
  )
  (_to_mu): Linear(in_features=100, out_features=1, bias=True)
  (_to_logvar): Linear(in_features=100, out_features=1, bias=True)
)
</pre></div></div>
</div>
<p>The decoder can be an ordinary MLP as in the autoencoder case.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">initial_batchnorm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now, the TVAE can be constructed and trained.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deeptime.decomposition.deep</span> <span class="kn">import</span> <span class="n">TVAE</span>

<span class="n">tvae</span> <span class="o">=</span> <span class="n">TVAE</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="n">tvae</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">loader_train</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">validation_loader</span><span class="o">=</span><span class="n">loader_val</span><span class="p">)</span>
<span class="n">tvae_model</span> <span class="o">=</span> <span class="n">tvae</span><span class="o">.</span><span class="n">fetch_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Also here we can have a look at the loss:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="o">*</span><span class="n">tvae</span><span class="o">.</span><span class="n">train_losses</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="o">*</span><span class="n">tvae</span><span class="o">.</span><span class="n">validation_losses</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_27_0.png" src="../_images/notebooks_tae_27_0.png" />
</div>
</div>
<p>And again, the network separates the two distributions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">traj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">tvae_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">traj</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cm</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_tae_29_0.png" src="../_images/notebooks_tae_29_0.png" />
</div>
</div>
<p class="rubric">References</p>
<p id="id3"><dl class="footnote brackets">
<dt class="label" id="footcite-wehmeyer2018timelagged"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Christoph Wehmeyer and Frank Noé. Time-lagged autoencoders: deep learning of slow collective variables for molecular kinetics. <em>J. Chem. Phys.</em>, 148(24):241703, jun 2018. <a class="reference external" href="https://doi.org/10.1063/1.5011399">doi:10.1063/1.5011399</a>.</p>
</dd>
<dt class="label" id="footcite-kingma2013auto"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Diederik P Kingma and Max Welling. Auto-encoding variational bayes. <em>arXiv preprint arXiv:1312.6114</em>, 2013.</p>
</dd>
</dl>
</p>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
<script src="../_static/scrollbar.js"></script>

  </body>
</html>